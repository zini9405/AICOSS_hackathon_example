{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9313d46f-f473-461f-834e-876f6ff02468",
   "metadata": {},
   "source": [
    "# IMDB 감정 분류 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8aa26a-3307-493b-802b-190cb95e25b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (2.3.1)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: filelock in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: tqdm in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torchtext) (4.66.4)\n",
      "Requirement already satisfied: requests in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torchtext) (2.32.2)\n",
      "Requirement already satisfied: numpy in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from torchtext) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.3.7-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from requests->torchtext) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from requests->torchtext) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from requests->torchtext) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.3.7-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m605.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow, multidict, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, torchtext, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.3.7 aiohttp-3.10.3 aiosignal-1.3.1 datasets-2.21.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-17.0.0 torchtext-0.18.0 xxhash-3.5.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchtext datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b93b34-5379-451c-ba23-251d419d4b06",
   "metadata": {},
   "source": [
    "# 1. Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c3429c-41b5-42e2-b5d8-124ccdbc6565",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# IMDB 데이터셋 로드 및 토크나이저 설정\n",
    "dataset = load_dataset(\"imdb\")\n",
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c1944-17e4-450c-a9b4-ce52d4ebe888",
   "metadata": {},
   "source": [
    "# 2. Pre-process & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbb8c65b-072a-4f3f-879f-89332d35e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 구축\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(dataset['train']['text']), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# 데이터 전처리\n",
    "def preprocess(text):\n",
    "    return torch.tensor(vocab(tokenizer(text)), dtype=torch.long)\n",
    "\n",
    "# 데이터 로더 설정\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = [preprocess(text) for text in texts]\n",
    "    labels = torch.tensor(labels, dtype=torch.float)\n",
    "    return nn.utils.rnn.pad_sequence(texts, batch_first=True), labels\n",
    "\n",
    "train_loader = DataLoader(list(zip(dataset['train']['text'], dataset['train']['label'])), \n",
    "                          batch_size=32, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef56bbb-91ed-4fc9-a6e7-03b0a82de04c",
   "metadata": {},
   "source": [
    "# 3. model\n",
    "# 3-1. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f11e669-9f9d-439e-bb9b-abe39fa81b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_ih = nn.Linear(input_size, hidden_size)\n",
    "        self.W_hh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        hidden = self.tanh(self.W_ih(x) + self.W_hh(hidden))\n",
    "        return hidden\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn_cell = RNNCell(embedding_dim, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        hidden = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
    "        for t in range(x.size(1)):\n",
    "            hidden = self.rnn_cell(x[:, t, :], hidden)\n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591a23d-3f32-4aee-9c36-e0ea5bab40ba",
   "metadata": {},
   "source": [
    "# 3-2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e76379-ba25-44e4-954b-51cfbe83eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_ii = nn.Linear(input_size, hidden_size)\n",
    "        self.W_if = nn.Linear(input_size, hidden_size)\n",
    "        self.W_ig = nn.Linear(input_size, hidden_size)\n",
    "        self.W_io = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.W_hi = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_hf = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_hg = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_ho = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        i = self.sigmoid(self.W_ii(x) + self.W_hi(hidden))\n",
    "        f = self.sigmoid(self.W_if(x) + self.W_hf(hidden))\n",
    "        g = self.tanh(self.W_ig(x) + self.W_hg(hidden))\n",
    "        o = self.sigmoid(self.W_io(x) + self.W_ho(hidden))\n",
    "        cell = f * cell + i * g\n",
    "        hidden = o * self.tanh(cell)\n",
    "        return hidden, cell\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm_cell = LSTMCell(embedding_dim, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        hidden = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
    "        cell = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
    "        for t in range(x.size(1)):\n",
    "            hidden, cell = self.lstm_cell(x[:, t, :], hidden, cell)\n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a9468-6e11-46fe-8166-f0326368ba51",
   "metadata": {},
   "source": [
    "# 3-3. GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d103ba0-2111-41e7-a172-a7478218f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_ir = nn.Linear(input_size, hidden_size)\n",
    "        self.W_iz = nn.Linear(input_size, hidden_size)\n",
    "        self.W_in = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.W_hr = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_hz = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_hn = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        r = self.sigmoid(self.W_ir(x) + self.W_hr(hidden))\n",
    "        z = self.sigmoid(self.W_iz(x) + self.W_hz(hidden))\n",
    "        n = self.tanh(self.W_in(x) + r * self.W_hn(hidden))\n",
    "        hidden = (1 - z) * n + z * hidden\n",
    "        return hidden\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru_cell = GRUCell(embedding_dim, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        hidden = torch.zeros(x.size(0), self.hidden_size).to(x.device)\n",
    "        for t in range(x.size(1)):\n",
    "            hidden = self.gru_cell(x[:, t, :], hidden)\n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a3e1e-4192-477c-a955-37d5cf0f4124",
   "metadata": {},
   "source": [
    "# 4. model & Hyper Parameters & loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77447ae2-4e1a-4a25-adce-1450223d785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "\n",
    "## RNN, LSTM, GRU 중 하나를 선택\n",
    "# model = RNN(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "# model = LSTM(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "model = GRU(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7421e-0e2c-4ecb-a72d-1f9b2985c403",
   "metadata": {},
   "source": [
    "# 5. train + (val) <- 직접 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef78621f-395f-442c-ad50-1e53555f22b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/782], Loss: 0.7042\n",
      "Epoch [1/10], Step [20/782], Loss: 0.7562\n",
      "Epoch [1/10], Step [30/782], Loss: 0.7053\n",
      "Epoch [1/10], Step [40/782], Loss: 0.6875\n",
      "Epoch [1/10], Step [50/782], Loss: 0.7044\n",
      "Epoch [1/10], Step [60/782], Loss: 0.7264\n",
      "Epoch [1/10], Step [70/782], Loss: 0.7282\n",
      "Epoch [1/10], Step [80/782], Loss: 0.6826\n",
      "Epoch [1/10], Step [90/782], Loss: 0.6959\n",
      "Epoch [1/10], Step [100/782], Loss: 0.6926\n",
      "Epoch [1/10], Step [110/782], Loss: 0.6994\n",
      "Epoch [1/10], Step [120/782], Loss: 0.6947\n",
      "Epoch [1/10], Step [130/782], Loss: 0.7501\n",
      "Epoch [1/10], Step [140/782], Loss: 0.6793\n",
      "Epoch [1/10], Step [150/782], Loss: 0.6980\n",
      "Epoch [1/10], Step [160/782], Loss: 0.6915\n",
      "Epoch [1/10], Step [170/782], Loss: 0.7038\n",
      "Epoch [1/10], Step [180/782], Loss: 0.6863\n",
      "Epoch [1/10], Step [190/782], Loss: 0.7038\n",
      "Epoch [1/10], Step [200/782], Loss: 0.6918\n",
      "Epoch [1/10], Step [210/782], Loss: 0.7034\n",
      "Epoch [1/10], Step [220/782], Loss: 0.6911\n",
      "Epoch [1/10], Step [230/782], Loss: 0.7081\n",
      "Epoch [1/10], Step [240/782], Loss: 0.6671\n",
      "Epoch [1/10], Step [250/782], Loss: 0.7007\n",
      "Epoch [1/10], Step [260/782], Loss: 0.6833\n",
      "Epoch [1/10], Step [270/782], Loss: 0.7031\n",
      "Epoch [1/10], Step [280/782], Loss: 0.6585\n",
      "Epoch [1/10], Step [290/782], Loss: 0.6821\n",
      "Epoch [1/10], Step [300/782], Loss: 0.6895\n",
      "Epoch [1/10], Step [310/782], Loss: 0.7035\n",
      "Epoch [1/10], Step [320/782], Loss: 0.7015\n",
      "Epoch [1/10], Step [330/782], Loss: 0.6886\n",
      "Epoch [1/10], Step [340/782], Loss: 0.6986\n",
      "Epoch [1/10], Step [350/782], Loss: 0.7331\n",
      "Epoch [1/10], Step [360/782], Loss: 0.7114\n",
      "Epoch [1/10], Step [370/782], Loss: 0.6958\n",
      "Epoch [1/10], Step [380/782], Loss: 0.7472\n",
      "Epoch [1/10], Step [390/782], Loss: 0.6801\n",
      "Epoch [1/10], Step [400/782], Loss: 0.7182\n",
      "Epoch [1/10], Step [410/782], Loss: 0.7026\n",
      "Epoch [1/10], Step [420/782], Loss: 0.6924\n",
      "Epoch [1/10], Step [430/782], Loss: 0.6949\n",
      "Epoch [1/10], Step [440/782], Loss: 0.6892\n",
      "Epoch [1/10], Step [450/782], Loss: 0.7041\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 172\u001b[0m\n\u001b[1;32m    169\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels)\n\u001b[1;32m    171\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 172\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    175\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/lee/anaconda3/envs/2024/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "log_interval = 100  # 중간 결과를 출력할 배치 간격\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (texts, labels) in enumerate(train_loader):\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Complete, Average Loss: {epoch_loss/len(train_loader):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
